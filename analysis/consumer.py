import asyncio
import json
import logging
import time

from aiokafka import AIOKafkaConsumer

from analysis import handle_analysis
from config import KAFKA_CONFIG
from dlq_producer import send_to_dlq

# ë¡œê·¸ ì„¤ì •
logger = logging.getLogger("consumer")

# ì„¤ì •
MAX_RETRY = 3


class SubmitMonitor:
    """
    Submit ë¶„ì„ ì¶”ì ìš© í´ëž˜ìŠ¤
    """
    is_first = False
    start_time = time.time()

    def __init__(self, submit_size: int, label: str):
        self.submit_size = submit_size
        self.label = label
        self.count = 0
        self.success = 0
        self.fail = 0

    def start_new(self, label: str) -> None:
        self.label = label
        self.count = 0
        self.success = 0
        self.fail = 0

    def log_result(self, success: bool = True) -> bool:
        self.count += 1
        if success:
            self.success += 1
        else:
            self.fail += 1

        if self.count >= self.submit_size:
            elapsed = time.time() - self.start_time
            print(f"\nðŸ“¦ Submit '{self.label}' ì™„ë£Œ")
            print(f"   âœ… ì„±ê³µ: {self.success}ê°œ")
            print(f"   âŒ ì‹¤íŒ¨: {self.fail}ê°œ")
            print(f"   â± ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ\n")
            return True
        return False


# ì „ì—­ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
monitor = SubmitMonitor(submit_size=10000, label="Submit 1")
submit_number = 1


async def process_message(message: dict, retry_cnt: int = 0) -> None:
    """
    ë©”ì‹œì§€ ì²˜ë¦¬

    Args:
        message (dict): Consumerê°€ ë°›ì€ ë©”ì‹œì§€
        retry_cnt (int): ìž¬ì‹œë„ ì¹´ìš´íŠ¸
    """
    global submit_number, monitor
    if not monitor.is_first:
        monitor.start_time = time.time()
        monitor.is_first = True

    try:
        data = json.loads(message.value.decode("utf-8"))
        await handle_analysis(data)
        success = True
    except Exception as e:
        logger.error(f"âŒ [{retry_cnt}/{MAX_RETRY}] ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        if retry_cnt >= MAX_RETRY:
            logger.info(f"[{data.get('consulting_id', 'unknown')}] ë¶„ì„ ìž¬ì‹œë„ ì´ˆê³¼. DLQë¡œ ì „ë‹¬")
            await send_to_dlq(data)
        else:
            await process_message(message, retry_cnt + 1)
        success = False

    is_submit_done = monitor.log_result(success)
    if is_submit_done:
        submit_number += 1
        monitor.start_new(label=f"Submit {submit_number}")


async def consume_worker(worker_id: int) -> None:
    """
    ë¹„ë™ê¸° Consumer ìƒì„± ë° ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°

    Args:
        worker_id (int): Worker ID
    """
    logger.info(f"ì›Œì»¤ #{worker_id} ì‹œìž‘")
    consumer = AIOKafkaConsumer(
        KAFKA_CONFIG["topic"],
        bootstrap_servers=KAFKA_CONFIG["bootstrap_servers"],
        group_id=KAFKA_CONFIG["group_id"],
        enable_auto_commit=True,
        auto_offset_reset="earliest"
    )
    await consumer.start()
    try:
        async for message in consumer:
            logger.info(f"[# {worker_id}] ë©”ì‹œì§€ ìˆ˜ì‹ : {message.key} {message.offset}")
            await process_message(message)
    finally:
        await consumer.stop()


async def start_kafka_workers() -> None:
    """
    Worker ìˆ˜ ëŒ€ë¡œ Consumer ìž‘ì—… ì‹œìž‘
    """
    workers = [consume_worker(i) for i in range(KAFKA_CONFIG["num_workers"])]
    await asyncio.gather(*workers)

